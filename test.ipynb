{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30de7ff6",
   "metadata": {},
   "source": [
    "Importing Kaggle Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0004e312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeevin/miniconda3/envs/paynet-test/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jeevin/.cache/kagglehub/datasets/jinquan/cc-sample-data/versions/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/07/21 00:59:04 WARN Utils: Your hostname, jeevin, resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/07/21 00:59:04 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/21 00:59:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from kagglehub import dataset_download\n",
    "#remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json, to_timestamp, split, when, lower, round as sp_round, from_utc_timestamp, date_format, udf\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, IntegerType, LongType\n",
    "import re\n",
    "\n",
    "path: str = dataset_download(\"jinquan/cc-sample-data\")\n",
    "\n",
    "print(path)\n",
    "\n",
    "spark = SparkSession.builder.appName(\"payNet\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a67be3f",
   "metadata": {},
   "source": [
    "Load JSON and clean up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d95900d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              street|\n",
      "+--------------------+\n",
      "|      561 Perry Cove|\n",
      "|43039 Riley Green...|\n",
      "|594 White Dale Su...|\n",
      "|9443 Cynthia Cour...|\n",
      "|    408 Bradley Rest|\n",
      "|   4655 David Island|\n",
      "|889 Sarah Station...|\n",
      "|231 Flores Pass S...|\n",
      "|6888 Hicks Stream...|\n",
      "|21326 Taylor Squa...|\n",
      "|1831 Faith View S...|\n",
      "|43576 Kristina Is...|\n",
      "|    3337 Lisa Divide|\n",
      "|5916 Susan Bridge...|\n",
      "|1632 Cohen Drive ...|\n",
      "|     870 Rocha Drive|\n",
      "|44259 Beth Statio...|\n",
      "|4923 Campbell Pin...|\n",
      "|268 Hayes Rue Sui...|\n",
      "|  269 Sanchez Rapids|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "+----------+---------------------+-------------------+----------------------------------------+-------------+------+-----------+---------+------+------------------------------+------------------------+-----+-----+-------+---------+--------+---------------------------------------------+----------+--------------------------------+---------+----------+--------+-------------+----------------------+----------------+-----------+\n",
      "|Unnamed: 0|trans_date_trans_time|cc_num             |merchant                                |category     |amt   |first      |last     |gender|street                        |city                    |state|zip  |lat    |long     |city_pop|job                                          |dob       |trans_num                       |merch_lat|merch_long|is_fraud|merch_zipcode|merch_last_update_time|merch_eff_time  |cc_bic     |\n",
      "+----------+---------------------+-------------------+----------------------------------------+-------------+------+-----------+---------+------+------------------------------+------------------------+-----+-----+-------+---------+--------+---------------------------------------------+----------+--------------------------------+---------+----------+--------+-------------+----------------------+----------------+-----------+\n",
      "|0         |2019-01-01 00:00:18  |2703186189652095   |fraud_Rippin, Kub and Mann              |misc_net     |4.97  |Jennifer   |Banks    |F     |561 Perry Cove                |Moravian Falls          |NC   |28654|36.0788|-81.1781 |3495    |Psychologist, counselling                    |1988-03-09|0b242abb623afc578575680df30655b9|36.01129 |-82.04832 |0       |28705        |1325376018666         |1325376018798532|CITIUS33CHI|\n",
      "|1         |2019-01-01 00:00:44  |630423337322       |fraud_Heller, Gutmann and Zieme         |grocery_pos  |107.23|Stephanie  |Gill     |F     |43039 Riley Greens Suite 393  |Orient                  |WA   |99160|48.8878|-118.2105|149     |Special educational needs teacher            |1978-06-21|1f76529f8574734946361c461b024d99|49.159046|-118.18646|0       |NULL         |132537604479          |1325376044867960|ADMDUS41   |\n",
      "|2         |2019-01-01 00:00:51  |38859492057661     |fraud_Lind-Buckridge                    |entertainment|220.11|Edward     |Sanchez  |M     |594 White Dale Suite 530      |Malad City              |ID   |83252|42.1808|-112.262 |4154    |Nature conservation officer                  |1962-01-19|a1a22d70485983eac12b5b88dad1cf95|43.150703|-112.15448|0       |83236        |1325376051286         |1325376051506840|NULL       |\n",
      "|3         |2019-01-01 00:01:16  |3534093764340240   |fraud_Kutch, Hermiston and Farrell      |gas_transport|45.0  |Jeremy     |White    |M     |9443 Cynthia Court Apt. 038   |Boulder                 |MT   |59632|46.2306|-112.1138|1939    |Patent attorney                              |1967-01-12|6b849c168bdad6f867558c3793159a81|47.034332|-112.56107|0       |NULL         |1325376076365         |1325376076794698|DEUTUS33TRF|\n",
      "|4         |2019-01-01 00:03:06  |375534208663984    |fraud_Keeling-Crist                     |misc_pos     |41.96 |Tyler      |Garcia   |M     |408 Bradley Rest              |Doe Hill                |VA   |24433|38.4207|-79.4629 |99      |Dance movement psychotherapist               |1986-03-28|a41d7549acf90789359a9aa5346dcb46|38.675   |-78.63246 |0       |22844        |132537618681          |1325376186746376|APBCUS61   |\n",
      "|5         |2019-01-01 00:04:08  |4767265376804500   |fraud_Stroman, Hudson and Erdman        |gas_transport|94.63 |Jennifer   |Conner   |F     |4655 David Island             |Dublin                  |PA   |18917|40.375 |-75.2045 |2158    |Transport planner                            |1961-06-19|189a841a0a8ba03058526bcfe566aab5|40.65338 |-76.152664|0       |17972        |1325376248483         |1325376248271406|APBCUS61   |\n",
      "|6         |2019-01-01 00:04:42  |30074693890476     |fraud_Rowe-Vandervort                   |grocery_net  |44.54 |Kelsey     |Richards |F     |889 Sarah Station Suite 624   |Holcomb                 |KS   |67851|37.9931|-100.9893|2691    |Arboriculturist                              |1993-08-16|83ec1cc84142af6e2acf10c44949e720|37.162704|-100.15337|0       |NULL         |1325376282247         |1325376282274130|APBCUS61   |\n",
      "|7         |2019-01-01 00:05:08  |6011360759745864   |fraud_Corwin-Collins                    |gas_transport|71.65 |Steven     |Williams |M     |231 Flores Pass Suite 720     |Edinburg                |VA   |22824|38.8432|-78.6003 |6018    |Designer, multimedia                         |1947-08-21|6d294ed2cc447d2c71c7171a3d54967c|38.94809 |-78.5403  |0       |22644        |1325376308152         |1325376308837349|NULL       |\n",
      "|8         |2019-01-01 00:05:18  |4922710831011201   |fraud_Herzog Ltd                        |misc_pos     |4.27  |Heather    |Chase    |F     |6888 Hicks Stream Suite 954   |Manor                   |PA   |15665|40.3359|-79.6607 |1472    |Public affairs consultant                    |1941-03-07|fc28024ce480f8ef21a32d64c93a29f5|40.351814|-79.958145|0       |15236        |1325376318278         |1325376318245892|ACEEUS31   |\n",
      "|9         |2019-01-01 00:06:01  |2720830304681674   |fraud_Schoen, Kuphal and Nitzsche       |grocery_pos  |198.39|Melissa    |Aguilar  |F     |21326 Taylor Squares Suite 708|Clarksville             |TN   |37040|36.522 |-87.349  |151785  |Pathologist                                  |1974-03-28|3b9014ea8fb80bd65de0b1463b00b00e|37.1792  |-87.48538 |0       |42442        |1325376361857         |1325376361965234|DEUTUS33TRF|\n",
      "|10        |2019-01-01 00:06:23  |4642894980163      |fraud_Rutherford-Mertz                  |grocery_pos  |24.74 |Eddie      |Mendez   |M     |1831 Faith View Suite 653     |Clarinda                |IA   |51632|40.7491|-95.038  |7297    |IT trainer                                   |1990-07-13|d71c95ab6b7356dd74389d41df429c87|40.27589 |-96.01155 |0       |68348        |1325376383455         |1325376383967287|NULL       |\n",
      "|11        |2019-01-01 00:06:53  |377234009633447    |fraud_Kerluke-Abshire                   |shopping_net |7.77  |Theresa    |Blackwell|F     |43576 Kristina Islands        |Shenandoah Junction     |WV   |25442|39.3716|-77.8229 |1925    |Systems developer                            |1966-02-14|3c74776e558f1499a7824b556e474b1d|40.103867|-78.62446 |0       |15554        |1325376413859         |1325376413912233|DEUTUS33TRF|\n",
      "|12        |2019-01-01 00:06:56  |180042946491150    |fraud_Lockman Ltd                       |grocery_pos  |71.22 |Charles    |Robles   |M     |3337 Lisa Divide              |Saint Petersburg        |FL   |33710|27.7898|-82.7243 |341043  |Engineer, land                               |1989-02-28|c1d9a7ddb1e34639fe82758de97f4abf|27.630592|-82.30889 |0       |33598        |1325376416443         |1325376416569264|DEUTUS33TRF|\n",
      "|13        |2019-01-01 00:07:27  |5559857416065248   |fraud_Kiehn Inc                         |grocery_pos  |96.29 |Jack       |Hill     |M     |5916 Susan Bridge Apt. 939    |Grenada                 |CA   |96038|41.6125|-122.5258|589     |Systems analyst                              |1945-12-21|413636e759663f264aae1819a4d4f231|41.65752 |-122.23035|0       |NULL         |1325376447771         |1325376447442465|ACEEUS31   |\n",
      "|14        |2019-01-01 00:09:03  |3514865930894695   |fraud_Beier-Hyatt                       |shopping_pos |7.77  |Christopher|Castaneda|M     |1632 Cohen Drive Suite 639    |High Rolls Mountain Park|NM   |88325|32.9396|-105.8189|899     |Naval architect                              |1967-08-30|8a6293af5ed278dea14448ded2685fea|32.86326 |-106.5202 |0       |NULL         |1325376543282         |132537654399153 |ACEEUS31   |\n",
      "|15        |2019-01-01 00:09:20  |6011999606625827   |fraud_Schmidt and Sons                  |shopping_net |3.26  |Ronald     |Carson   |M     |870 Rocha Drive               |Harrington Park         |NJ   |7640 |40.9918|-73.98   |4664    |Radiographer, diagnostic                     |1965-06-30|baae0b096835c975857eea7e28dde3dc|41.831173|-74.335556|0       |12446        |1325376560435         |1325376560448213|CITIUS33CHI|\n",
      "|16        |2019-01-01 00:10:49  |6011860238257910   |fraud_Lebsack and Sons                  |misc_net     |327.0 |Lisa       |Mendez   |F     |44259 Beth Station Suite 215  |Lahoma                  |OK   |73754|36.385 |-98.0727 |1078    |Programme researcher, broadcasting/film/video|1952-07-06|991c04803b4d4eeab30d6245a872e3d3|36.38409 |-99.04847 |0       |73852        |1325376649369         |132537664977977 |CITIUS33CHI|\n",
      "|17        |2019-01-01 00:10:58  |3565423334076143   |fraud_Mayert Group                      |shopping_pos |341.67|Nathan     |Thomas   |M     |4923 Campbell Pines Suite 717 |Carlisle                |IN   |47838|38.9763|-87.3667 |4081    |Energy engineer                              |1938-03-15|f12cf52be2175703db789a4644c32f25|38.67449 |-88.30576 |0       |62824        |1325376658125         |1325376658780653|NULL       |\n",
      "|18        |2019-01-01 00:11:14  |2348245054386329   |fraud_Konopelski, Schneider and Hartmann|food_dining  |63.07 |Justin     |Gay      |M     |268 Hayes Rue Suite 811       |Harborcreek             |PA   |16421|42.1767|-79.9416 |2518    |Event organiser                              |1946-02-02|8500f3d459047eac8443307b1e8296e5|41.430275|-79.49255 |0       |16364        |1325376674800         |1325376674645606|APBCUS61   |\n",
      "|19        |2019-01-01 00:12:34  |4956828990005111019|fraud_Schultz, Simonis and Little       |grocery_pos  |44.71 |Kenneth    |Robinson |M     |269 Sanchez Rapids            |Elizabeth               |NJ   |7208 |40.6747|-74.2239 |124967  |Operational researcher                       |1980-12-21|09eff9c806365e2a6be12c1bbab3d70e|40.07959 |-74.84808 |0       |08016        |1325376754863         |132537675433224 |NULL       |\n",
      "+----------+---------------------+-------------------+----------------------------------------+-------------+------+-----------+---------+------+------------------------------+------------------------+-----+-----+-------+---------+--------+---------------------------------------------+----------+--------------------------------+---------+----------+--------+-------------+----------------------+----------------+-----------+\n",
      "only showing top 20 rows\n",
      "root\n",
      " |-- Unnamed: 0: integer (nullable = true)\n",
      " |-- trans_date_trans_time: timestamp (nullable = true)\n",
      " |-- cc_num: string (nullable = true)\n",
      " |-- merchant: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- amt: float (nullable = true)\n",
      " |-- first: string (nullable = true)\n",
      " |-- last: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- street: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- zip: string (nullable = true)\n",
      " |-- lat: float (nullable = true)\n",
      " |-- long: float (nullable = true)\n",
      " |-- city_pop: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- trans_num: string (nullable = true)\n",
      " |-- merch_lat: float (nullable = true)\n",
      " |-- merch_long: float (nullable = true)\n",
      " |-- is_fraud: integer (nullable = true)\n",
      " |-- merch_zipcode: string (nullable = true)\n",
      " |-- merch_last_update_time: long (nullable = true)\n",
      " |-- merch_eff_time: long (nullable = true)\n",
      " |-- cc_bic: string (nullable = true)\n",
      "\n",
      "Checking for conversion failures...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 92:>                                                         (0 + 7) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------+------+--------+--------+---+-----+----+------+------+----+-----+---+---+----+--------+---+---+---------+---------+----------+--------+-------------+----------------------+--------------+------+\n",
      "|Unnamed: 0|trans_date_trans_time|cc_num|merchant|category|amt|first|last|gender|street|city|state|zip|lat|long|city_pop|job|dob|trans_num|merch_lat|merch_long|is_fraud|merch_zipcode|merch_last_update_time|merch_eff_time|cc_bic|\n",
      "+----------+---------------------+------+--------+--------+---+-----+----+------+------+----+-----+---+---+----+--------+---+---+---------+---------+----------+--------+-------------+----------------------+--------------+------+\n",
      "+----------+---------------------+------+--------+--------+---+-----+----+------+------+----+-----+---+---+----+--------+---+---+---------+---------+----------+--------+-------------+----------------------+--------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as sf\n",
    "\n",
    "# Read the JSON data from the file\n",
    "df = spark.read.json(path)\n",
    "\n",
    "def clean_json_string(json_str):\n",
    "    \"\"\"\n",
    "    Clean JSON string by:\n",
    "    1. Removing all backslashes\n",
    "    2. Removing quotes around JSON objects (e.g., \"{ }\" becomes { })\n",
    "    \"\"\"\n",
    "    if json_str is None:\n",
    "        return None\n",
    "    \n",
    "    # Remove all backslashes\n",
    "    cleaned = json_str.replace(\"\\\\\", \"\")\n",
    "    \n",
    "    # Remove quotes around JSON objects - pattern: \"{ ... }\"\n",
    "    # This regex finds quoted JSON objects and removes the outer quotes\n",
    "    cleaned = re.sub(r'\"\\s*\\{\\s*(.*?)\\s*\\}\\s*\"', r'{\\1}', cleaned)\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "# Register UDF\n",
    "clean_json_udf = udf(clean_json_string, StringType())\n",
    "\n",
    "# Apply cleaning to the personal_detail column\n",
    "df_cleaned = df.withColumn(\"personal_detail\", clean_json_udf(sf.col(\"personal_detail\")))\n",
    "\n",
    "# Define schema for address (nested within personal_detail) - all strings initially\n",
    "address_schema = StructType([\n",
    "    StructField(\"street\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"zip\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Define schema for personal_detail - all strings initially\n",
    "personal_schema = StructType([\n",
    "    StructField(\"person_name\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"address\", address_schema, True),\n",
    "    StructField(\"lat\", StringType(), True),\n",
    "    StructField(\"long\", StringType(), True),\n",
    "    StructField(\"city_pop\", StringType(), True),\n",
    "    StructField(\"job\", StringType(), True),\n",
    "    StructField(\"dob\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Parse the cleaned JSON string into proper columns (overwrite the original column)\n",
    "df_with_parsed_personal = df_cleaned.withColumn(\"personal_detail\", sf.from_json(sf.col(\"personal_detail\"), personal_schema))\n",
    "\n",
    "# for debugging\n",
    "# df_with_parsed_personal.select(col(\"personal_detail.person_name\")).show()\n",
    "df_with_parsed_personal.select(col(\"personal_detail.address.street\")).show()\n",
    "\n",
    "# Process name splitting for 'first' and 'last' names with improved robustness.\n",
    "df_with_names = df_with_parsed_personal.withColumn(\n",
    "    \"cleaned_person_name\",\n",
    "    sf.when(sf.col(\"personal_detail.person_name\").isNotNull(),\n",
    "        sf.trim(\n",
    "            sf.regexp_replace( # Normalize multiple spaces to single space\n",
    "                sf.regexp_replace( # Replace all non-alphanumeric characters (except spaces) with a single space\n",
    "                    sf.regexp_replace( # Remove specific trailing strings like 'eeeee' and 'N' followed by 4 or more '0' or 'O' (case-insensitive)\n",
    "                        sf.regexp_replace(sf.col(\"personal_detail.person_name\"), r\"(?i),?eeeee$\", \"\"),\n",
    "                        r\"(?i),?\\s*N[0O]{4,}$\", \"\" # Updated regex to handle N0000, NOOOO etc.\n",
    "                    ),\n",
    "                    r\"[^a-zA-Z0-9\\s]\", \" \" # Replace any character that is NOT a letter, number, or whitespace with a space. This will catch /, !, @, |, and also the comma if it's not part of a \"Lastname, Firstname\" pattern.\n",
    "                ),\n",
    "                r\"\\s+\", \" \" # Normalize multiple spaces to single space\n",
    "            )\n",
    "        )\n",
    "    ).otherwise(None)\n",
    ")\n",
    "\n",
    "df_with_names = df_with_names \\\n",
    "    .withColumn(\"name_parts\", sf.split(sf.col(\"cleaned_person_name\"), \" \")) \\\n",
    "    .withColumn(\"first\", \n",
    "        sf.when(sf.size(sf.col(\"name_parts\")) >= 1, sf.trim(sf.element_at(sf.col(\"name_parts\"), 1)))\n",
    "        .otherwise(None)\n",
    "    ) \\\n",
    "    .withColumn(\"last\", \n",
    "        sf.when(sf.size(sf.col(\"name_parts\")) > 1, \n",
    "                sf.trim(sf.concat_ws(\" \", sf.slice(sf.col(\"name_parts\"), 2, sf.size(sf.col(\"name_parts\"))))))\n",
    "        .otherwise(None)\n",
    "    ) \\\n",
    "    .drop(\"cleaned_person_name\", \"name_parts\") # Drop intermediate columns\n",
    "\n",
    "\n",
    "# Flatten the personal_detail structure and address structure\n",
    "df_flattened = df_with_names.select(\n",
    "    # Original columns in desired order\n",
    "    sf.col(\"Unnamed: 0\"),\n",
    "    sf.col(\"trans_date_trans_time\"),\n",
    "    sf.col(\"cc_num\"),\n",
    "    sf.col(\"merchant\"),\n",
    "    sf.col(\"category\"),\n",
    "    sf.col(\"amt\"),\n",
    "    \n",
    "    sf.col(\"first\"),\n",
    "    sf.col(\"last\"),\n",
    "\n",
    "    # Personal details\n",
    "    sf.col(\"personal_detail.gender\").alias(\"gender\"),\n",
    "    \n",
    "    # Flattened address details\n",
    "    sf.col(\"personal_detail.address.street\").alias(\"street\"),\n",
    "    sf.col(\"personal_detail.address.city\").alias(\"city\"),\n",
    "    sf.col(\"personal_detail.address.state\").alias(\"state\"),\n",
    "    sf.col(\"personal_detail.address.zip\").alias(\"zip\"),\n",
    "    \n",
    "    # Location and demographic info\n",
    "    sf.col(\"personal_detail.lat\").alias(\"lat\"),\n",
    "    sf.col(\"personal_detail.long\").alias(\"long\"),\n",
    "    sf.col(\"personal_detail.city_pop\").alias(\"city_pop\"),\n",
    "    sf.col(\"personal_detail.job\").alias(\"job\"),\n",
    "    sf.col(\"personal_detail.dob\").alias(\"dob\"),\n",
    "    \n",
    "    # Transaction details\n",
    "    sf.col(\"trans_num\"),\n",
    "    sf.col(\"merch_lat\"),\n",
    "    sf.col(\"merch_long\"),\n",
    "    sf.col(\"is_fraud\"),\n",
    "    sf.col(\"merch_zipcode\"),\n",
    "    sf.col(\"merch_last_update_time\"),\n",
    "    sf.col(\"merch_eff_time\"),\n",
    "    sf.col(\"cc_bic\")\n",
    ")\n",
    "\n",
    "# Type conversions and rounding in one operation\n",
    "df_final = df_flattened.withColumns({\n",
    "    'Unnamed: 0': sf.col(\"Unnamed: 0\").cast(IntegerType()),\n",
    "    'trans_date_trans_time': sf.to_timestamp(sf.col(\"trans_date_trans_time\"), \"yyyy-MM-dd HH:mm:ss\"),\n",
    "    'amt': sf.round(sf.col(\"amt\").cast(FloatType()), 6),\n",
    "    'merch_lat': sf.round(sf.col(\"merch_lat\").cast(FloatType()), 6),\n",
    "    'merch_long': sf.round(sf.col(\"merch_long\").cast(FloatType()), 6),\n",
    "    'is_fraud': sf.col(\"is_fraud\").cast(IntegerType()),\n",
    "    'merch_eff_time': sf.col(\"merch_eff_time\").cast(LongType()),\n",
    "    'merch_last_update_time': sf.col(\"merch_last_update_time\").cast(LongType()),\n",
    "    'lat': sf.round(sf.col(\"lat\").cast(FloatType()), 6),\n",
    "    'long': sf.round(sf.col(\"long\").cast(FloatType()), 6),\n",
    "    'city_pop': sf.col(\"city_pop\").cast(IntegerType())\n",
    "})\n",
    "\n",
    "# Handle null values and \"NA\" strings for all string columns automatically\n",
    "string_columns = [field.name for field in df_final.schema.fields if field.dataType.typeName() == 'string']\n",
    "\n",
    "# Create dictionary for null value handling across all string columns\n",
    "null_handling_dict = {}\n",
    "for col_name in string_columns:\n",
    "    null_handling_dict[col_name] = sf.when(\n",
    "        (sf.lower(sf.col(col_name)) == \"na\") | \n",
    "        (sf.lower(sf.col(col_name)) == \"null\") | \n",
    "        (sf.col(col_name) == \"\"), \n",
    "        None\n",
    "    ).otherwise(sf.col(col_name))\n",
    "\n",
    "df_final = df_final.withColumns(null_handling_dict)\n",
    "\n",
    "# Show final result\n",
    "df_final.show(truncate=False)\n",
    "\n",
    "# Show schema to verify structure\n",
    "df_final.printSchema()\n",
    "\n",
    "# Optional: Show any conversion failures\n",
    "print(\"Checking for conversion failures...\")\n",
    "df_final.filter(sf.col(\"amt\").isNull() | sf.col(\"lat\").isNull() | sf.col(\"city_pop\").isNull()).show()\n",
    "\n",
    "# Save the cleaned data\n",
    "# df_final.write.mode(\"overwrite\").json(\"cleaned_output_path\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e98cebf",
   "metadata": {},
   "source": [
    "Infer insights from the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paynet-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
